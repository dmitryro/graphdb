use std::collections::{HashMap, HashSet};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::io::{Cursor, Read, Write};
use sled::{Config, Db, IVec, Tree, Batch};
use tokio::sync::{Mutex as TokioMutex, RwLock};
use tokio::time::{Duration, timeout};
use tokio::fs;
use log::{info, debug, warn, error};
use crate::storage_engine::config::{SledConfig, SledDaemon, SledDaemonPool, SledStorage, StorageConfig, DAEMON_REGISTRY_DB_PATH};
use crate::storage_engine::storage_utils::{create_edge_key, deserialize_edge, deserialize_vertex, serialize_edge, serialize_vertex};
use models::{Edge, Identifier, Vertex};
use models::errors::{GraphError, GraphResult};
use serde_json::Value;
use crate::daemon_registry::{GLOBAL_DAEMON_REGISTRY, DaemonMetadata};
use std::time::{SystemTime, UNIX_EPOCH};
use futures::future::join_all;
use uuid::Uuid;
use sysinfo::{System, Pid};

#[cfg(feature = "with-openraft-sled")]
use {
    async_trait::async_trait,
    openraft::{Config as RaftConfig, NodeId, Raft, RaftNetwork, RaftStorage, BasicNode},
    openraft_sled::SledRaftStorage,
    tokio::net::TcpStream,
    tokio::io::{AsyncReadExt, AsyncWriteExt},
};

impl SledDaemon {
    pub async fn new(config: &SledConfig) -> GraphResult<Self> {
        println!("===> TRYING TO INITIALIZE POOL");
        let db_path = config.path.join("db");
        info!("Initializing SledDaemon with path {:?}", db_path);
        debug!("Caller stack trace: {:#?}", std::backtrace::Backtrace::capture());

        // Ensure the database directory exists
        if db_path.exists() {
            if !db_path.is_dir() {
                warn!("Path {:?} exists but is not a directory, removing it", db_path);
                fs::remove_file(&db_path)
                    .await
                    .map_err(|e| GraphError::StorageError(format!("Failed to remove file at {:?}: {}", db_path, e)))?;
                info!("Creating directory at {:?}", db_path);
                fs::create_dir_all(&db_path)
                    .await
                    .map_err(|e| GraphError::StorageError(format!("Failed to create directory at {:?}: {}", db_path, e)))?;
            }
        } else {
            info!("Creating database directory at {:?}", db_path);
            fs::create_dir_all(&db_path)
                .await
                .map_err(|e| GraphError::StorageError(format!("Failed to create database directory at {:?}: {}", db_path, e)))?;
        }

        // Check for running processes that might conflict
        let port = config.port.ok_or_else(|| {
            GraphError::ConfigurationError("No port specified in SledConfig".to_string())
        })?;
        let mut system = System::new_all();
        system.refresh_all();
        let port_in_use = system.processes().values().any(|proc| {
            proc.cmd().iter().any(|arg| arg.to_string_lossy().contains(&port.to_string())) && 
            proc.name().to_string_lossy().contains("graphdb")
        });
        if port_in_use {
            error!("Port {} is already in use by another process", port);
            return Err(GraphError::StorageError(format!("Port {} is already in use", port)));
        }

        // Check daemon registry without cleanup
        let daemon_metadata = GLOBAL_DAEMON_REGISTRY.get_daemon_metadata(port).await?;
        if daemon_metadata.is_some() {
            warn!("Storage process already registered on port {}. Skipping cleanup.", port);
            // Do not unregister or clean locks
        }

        // Open sled DB without retries for lock contention
        debug!("Attempting to open Sled DB at {:?}", db_path);
        let db: Db = Config::new()
            .path(&db_path)
            .use_compression(config.use_compression)
            .cache_capacity(config.cache_capacity.unwrap_or(1024 * 1024 * 1024))
            .flush_every_ms(Some(100))
            .open()
            .map_err(|e| {
                error!("Failed to open Sled DB at {:?}: {}", db_path, e);
                GraphError::StorageError(format!(
                    "Failed to open Sled DB at {:?}: {}. Ensure no other process is using the database.",
                    db_path, e
                ))
            })?;
        let integrity_check = db.was_recovered();
        info!("Sled DB opened at {:?}, was_recovered: {}", db_path, integrity_check);

        // Open trees used by the system
        let vertices: Tree = db.open_tree("vertices").map_err(|e| GraphError::StorageError(e.to_string()))?;
        let edges: Tree = db.open_tree("edges").map_err(|e| GraphError::StorageError(e.to_string()))?;
        let kv_pairs: Tree = db.open_tree("kv_pairs").map_err(|e| GraphError::StorageError(e.to_string()))?;

        // Log key count to avoid unnecessary retrieval
        let kv_key_count = kv_pairs.len();
        let kv_keys: Vec<_> = kv_pairs.iter().keys().filter_map(|k| k.ok()).collect();
        info!("Initial kv_pairs key count at {:?}: {}, keys: {:?}", db_path, kv_key_count, kv_keys);

        #[cfg(feature = "with-openraft-sled")]
        let (raft, raft_storage) = {
            let raft_db_path = db_path.join("raft");
            if !raft_db_path.exists() {
                tokio::fs::create_dir_all(&raft_db_path)
                    .await
                    .map_err(|e| GraphError::Io(e))?;
            }
            let raft_storage = timeout(Duration::from_secs(5), SledRaftStorage::new(&raft_db_path))
                .await
                .map_err(|_| GraphError::StorageError(format!(
                    "Timeout initializing Raft storage at {:?}", raft_db_path
                )))?
                .map_err(|e| GraphError::StorageError(format!(
                    "Failed to initialize Raft storage at {:?}: {}", raft_db_path, e
                )))?;
            let raft_config = RaftConfig {
                cluster_name: "graphdb-cluster".to_string(),
                heartbeat_interval: 250,
                election_timeout_min: 1000,
                election_timeout_max: 2000,
                ..Default::default()
            };
            let raft = Raft::new(
                port as u64,
                Arc::new(raft_config),
                Arc::new(raft_storage.clone()),
                Arc::new(RaftTcpNetwork {}),
            )
            .await
            .map_err(|e| GraphError::StorageError(format!("Failed to initialize Raft: {}", e)))?;
            (Arc::new(raft), Arc::new(raft_storage))
        };

        #[cfg(not(feature = "with-openraft-sled"))]
        let (raft, raft_storage, node_id) = (None::<()>, None::<()>, 0);

        let daemon = Self {
            port,
            db_path,
            db: Arc::new(db),
            vertices,
            edges,
            kv_pairs,
            running: Arc::new(TokioMutex::new(true)),
            #[cfg(feature = "with-openraft-sled")]
            raft_storage,
            #[cfg(feature = "with-openraft-sled")]
            raft,
            #[cfg(feature = "with-openraft-sled")]
            node_id: port as u64,
        };

        // Register SIGTERM handler to gracefully close
        #[cfg(unix)]
        {
            let daemon_clone = Arc::new(daemon.clone());
            tokio::spawn(async move {
                let mut sigterm = tokio::signal::unix::signal(tokio::signal::unix::SignalKind::terminate())
                    .expect("Failed to register SIGTERM handler");
                while sigterm.recv().await.is_some() {
                    warn!("Received SIGTERM in SledDaemon at {:?}", chrono::Local::now());
                    if let Err(e) = daemon_clone.close().await {
                        error!("Failed to close SledDaemon on SIGTERM: {}", e);
                    } else {
                        info!("SledDaemon shutdown complete");
                    }
                }
            });
        }

        Ok(daemon)
    }

    // Unchanged methods from previous response
    pub async fn is_running(&self) -> bool {
        *self.running.lock().await
    }

    pub async fn close(&self) -> GraphResult<()> {
        info!("Closing SledDaemon at path {:?}", self.db_path);
        let db_flush = self.db.flush_async()
            .await
            .map_err(|e| GraphError::StorageError(format!("Failed to flush Sled DB: {}", e)))?;
        let vertices_flush = self.vertices.flush_async()
            .await
            .map_err(|e| GraphError::StorageError(format!("Failed to flush vertices tree: {}", e)))?;
        let edges_flush = self.edges.flush_async()
            .await
            .map_err(|e| GraphError::StorageError(format!("Failed to flush edges tree: {}", e)))?;
        let kv_pairs_flush = self.kv_pairs.flush_async()
            .await
            .map_err(|e| GraphError::StorageError(format!("Failed to flush kv_pairs tree: {}", e)))?;
        info!("Flushed SledDaemon at {:?}: db={} bytes, vertices={} bytes, edges={} bytes, kv_pairs={} bytes",
            self.db_path, db_flush, vertices_flush, edges_flush, kv_pairs_flush);
        *self.running.lock().await = false;
        Ok(())
    }

    pub fn db_path(&self) -> PathBuf {
        self.db_path.clone()
    }

    pub fn port(&self) -> u16 {
        self.port
    }

    #[cfg(feature = "with-openraft-sled")]
    pub async fn is_leader(&self) -> GraphResult<bool> {
        let metrics = self.raft.metrics().await;
        let is_leader = matches!(metrics.raft_state, openraft::RaftState::Leader);
        info!("Checking Raft leader status for node {} at path {:?}", self.node_id, self.db_path);
        Ok(is_leader)
    }

    async fn ensure_write_access(&self) -> GraphResult<()> {
        if !self.is_running().await {
            return Err(GraphError::StorageError(format!("Daemon at path {:?} is not running", self.db_path)));
        }
        #[cfg(feature = "with-openraft-sled")]
        {
            if !self.is_leader().await? {
                return Err(GraphError::StorageError(
                    format!("Node {} at path {:?} is not Raft leader, write access denied", self.node_id, self.db_path)
                ));
            }
        }
        Ok(())
    }

    fn serialize_to_ivec<T: serde::Serialize>(data: &T) -> GraphResult<IVec> {
        let mut cursor = Cursor::new(Vec::new());
        let serialized = serde_json::to_vec(data)
            .map_err(|e| GraphError::StorageError(format!("Serialization failed: {}", e)))?;
        cursor.write_all(&serialized)
            .map_err(|e| GraphError::StorageError(format!("Failed to write to cursor: {}", e)))?;
        let bytes = cursor.into_inner();
        Ok(IVec::from(bytes))
    }

    fn deserialize_from_ivec<T: serde::de::DeserializeOwned>(ivec: IVec) -> GraphResult<T> {
        let mut cursor = Cursor::new(ivec.to_vec());
        let mut bytes = Vec::new();
        cursor
            .read_to_end(&mut bytes)
            .map_err(|e| GraphError::StorageError(format!("Failed to read from cursor: {}", e)))?;
        serde_json::from_slice(&bytes)
            .map_err(|e| GraphError::StorageError(format!("Deserialization failed: {}", e)))
    }

    pub async fn insert(&self, key: &[u8], value: &[u8]) -> GraphResult<()> {
        self.ensure_write_access().await?;
        info!("Inserting key into kv_pairs at path {:?}", self.db_path);
        println!("==> IN INSERT - trying to insert key {:?}", key);

        timeout(Duration::from_secs(5), async {
            let pre_keys: Vec<_> = self.kv_pairs.iter().keys().filter_map(|k| k.ok()).collect();
            debug!("Keys before insert at {:?}: {:?}", self.db_path, pre_keys);

            let mut batch = Batch::default();
            batch.insert(key, value);
            self.kv_pairs
                .apply_batch(batch)
                .map_err(|e| GraphError::StorageError(format!("Failed to apply batch: {}", e)))?;

            let bytes_flushed = self.db.flush_async().await
                .map_err(|e| GraphError::StorageError(format!("Failed to flush DB: {}", e)))?;
            info!("Flushed {} bytes after insert at {:?}", bytes_flushed, self.db_path);
            println!("==> IN INSERT - flushed {} bytes", bytes_flushed);

            let persisted = self.kv_pairs
                .get(key)
                .map_err(|e| GraphError::StorageError(format!("Failed to verify insert: {}", e)))?;
            println!("==> IN INSERT - inserted key {:?} and value {:?}", key, persisted);
            if persisted.is_none() || persisted.as_ref().map(|v| v.as_ref()) != Some(value) {
                error!("Persistence verification failed for key at {:?}", self.db_path);
                return Err(GraphError::StorageError("Insert not persisted correctly".to_string()));
            }

            let keys: Vec<_> = self.kv_pairs
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            info!("Current kv_pairs keys at {:?}: {:?}", self.db_path, keys);
            println!("==> IN INSERT -  {:?}: {:?}", self.db_path, keys);

            #[cfg(feature = "with-openraft-sled")]
            {
                let request = openraft::raft::ClientWriteRequest::new(
                    openraft::EntryPayload::AppWrite {
                        key: key.to_vec(),
                        value: value.to_vec(),
                    }
                );
                self.raft.client_write(request).await
                    .map_err(|e| GraphError::StorageError(format!("Raft write failed: {}", e)))?;
                info!("Raft write replicated for key at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during insert".to_string()))?
    }

    pub async fn retrieve(&self, key: &[u8]) -> GraphResult<Option<Vec<u8>>> {
        if !self.is_running().await {
            return Err(GraphError::StorageError(format!("Daemon at path {:?} is not running", self.db_path)));
        }
        if key == b"test_key" {
            warn!("Retrieving test_key, caller stack trace: {:#?}", std::backtrace::Backtrace::capture());
        }
        info!("Retrieving key from kv_pairs at path {:?}", self.db_path);
        println!("==> RETRIEVE: Retrieving key from kv_pairs at path {:?} and key IS {:?}", self.db_path, key);

        let value = timeout(Duration::from_secs(5), async {
            let pre_keys: Vec<_> = self.kv_pairs.iter().keys().filter_map(|k| k.ok()).collect();
            debug!("Keys before retrieve at {:?}: {:?}", self.db_path, pre_keys);

            let opt = self.kv_pairs
                .get(key)
                .map_err(|e| GraphError::StorageError(format!("Failed to retrieve key: {}", e)))?;
            match opt {
                Some(ivec) => {
                    let mut cursor = Cursor::new(ivec.to_vec());
                    let mut bytes = Vec::new();
                    cursor
                        .read_to_end(&mut bytes)
                        .map_err(|e| GraphError::StorageError(format!("Failed to read from cursor: {}", e)))?;
                    Ok::<Option<Vec<u8>>, GraphError>(Some(bytes))
                }
                None => Ok::<Option<Vec<u8>>, GraphError>(None),
            }
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during retrieve".to_string()))??;

        let keys: Vec<_> = self.kv_pairs
            .iter()
            .keys()
            .filter_map(|k| k.ok())
            .collect();
        info!("Current kv_pairs keys at {:?}: {:?}", self.db_path, keys);
        println!("==> RETRIEVE: kv_pairs keys at {:?}: {:?} and value {:?}", self.db_path, keys, value);
        Ok(value)
    }

    pub async fn delete(&self, key: &[u8]) -> GraphResult<()> {
        self.ensure_write_access().await?;
        info!("Deleting key from kv_pairs at path {:?}", self.db_path);
        timeout(Duration::from_secs(5), async {
            let pre_keys: Vec<_> = self.kv_pairs.iter().keys().filter_map(|k| k.ok()).collect();
            debug!("Keys before delete at {:?}: {:?}", self.db_path, pre_keys);

            self.kv_pairs
                .remove(key)
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let bytes_flushed = self.db
                .flush_async()
                .await
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let keys: Vec<_> = self.kv_pairs
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            info!("Flushed {} bytes after delete at {:?}, current kv_pairs keys: {:?}", bytes_flushed, self.db_path, keys);
            #[cfg(feature = "with-openraft-sled")]
            {
                let request = openraft::raft::ClientWriteRequest::new(
                    openraft::EntryPayload::AppWrite {
                        key: key.to_vec(),
                        value: vec![],
                    }
                );
                self.raft.client_write(request).await
                    .map_err(|e| GraphError::StorageError(format!("Raft delete failed: {}", e)))?;
                info!("Raft delete replicated for key at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during delete".to_string()))?
    }

    pub async fn create_vertex(&self, vertex: &Vertex) -> GraphResult<()> {
        self.ensure_write_access().await?;
        let key = vertex.id.0.as_bytes();
        let value = Self::serialize_to_ivec(vertex)?;
        info!("Creating vertex with id {} at path {:?}", vertex.id, self.db_path);

        timeout(Duration::from_secs(5), async {
            let mut batch = Batch::default();
            batch.insert(key, value);
            self.vertices
                .apply_batch(batch)
                .map_err(|e| GraphError::StorageError(format!("Failed to apply batch for vertex: {}", e)))?;

            let bytes_flushed = self.db
                .flush_async()
                .await
                .map_err(|e| GraphError::StorageError(format!("Failed to flush DB: {}", e)))?;
            info!("Flushed {} bytes after creating vertex at {:?}", bytes_flushed, self.db_path);

            let persisted = self.vertices
                .get(key)
                .map_err(|e| GraphError::StorageError(format!("Failed to verify vertex insert: {}", e)))?;
            if persisted.is_none() {
                error!("Persistence verification failed for vertex id {} at {:?}", vertex.id, self.db_path);
                return Err(GraphError::StorageError("Vertex insert not persisted".to_string()));
            }

            let vertex_keys: Vec<_> = self.vertices
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            info!("Current vertices keys at {:?}: {:?}", self.db_path, vertex_keys);

            #[cfg(feature = "with-openraft-sled")]
            {
                let request = openraft::raft::ClientWriteRequest::new(
                    openraft::EntryPayload::AppWrite {
                        key: key.to_vec(),
                        value: vertex.id.0.as_bytes().to_vec(),
                    }
                );
                self.raft.client_write(request).await
                    .map_err(|e| GraphError::StorageError(format!("Raft vertex create failed: {}", e)))?;
                info!("Raft vertex create replicated at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during create_vertex".to_string()))?
    }

    pub async fn get_vertex(&self, id: &Uuid) -> GraphResult<Option<Vertex>> {
        if !self.is_running().await {
            return Err(GraphError::StorageError(format!("Daemon at path {:?} is not running", self.db_path)));
        }
        let key = id.as_bytes();
        info!("Retrieving vertex with id {} from path {:?}", id, self.db_path);

        let res = timeout(Duration::from_secs(5), async {
            let opt = self.vertices
                .get(key)
                .map_err(|e| GraphError::StorageError(format!("Failed to retrieve vertex: {}", e)))?;
            match opt {
                Some(ivec) => {
                    let vertex = Self::deserialize_from_ivec(ivec)?;
                    Ok::<Option<Vertex>, GraphError>(Some(vertex))
                }
                None => Ok::<Option<Vertex>, GraphError>(None),
            }
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during get_vertex".to_string()))??;

        let vertex_keys: Vec<_> = self.vertices
            .iter()
            .keys()
            .filter_map(|k| k.ok())
            .collect();
        info!("Current vertices keys at {:?}: {:?}", self.db_path, vertex_keys);
        Ok(res)
    }

    pub async fn update_vertex(&self, vertex: &Vertex) -> GraphResult<()> {
        self.delete_vertex(&vertex.id.0).await?;
        self.create_vertex(vertex).await
    }

    pub async fn delete_vertex(&self, id: &Uuid) -> GraphResult<()> {
        self.ensure_write_access().await?;
        let key = id.as_bytes();
        info!("Deleting vertex with id {} from path {:?}", id, self.db_path);
        timeout(Duration::from_secs(5), async {
            self.vertices
                .remove(key)
                .map_err(|e| GraphError::StorageError(e.to_string()))?;

            let mut batch = sled::Batch::default();
            let prefix = id.as_bytes();
            for item in self.edges.iter().keys() {
                let k = item.map_err(|e| GraphError::StorageError(e.to_string()))?;
                if k.starts_with(prefix) {
                    batch.remove(k);
                }
            }
            self.edges
                .apply_batch(batch)
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let bytes_flushed = self.db
                .flush_async()
                .await
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let vertex_keys: Vec<_> = self.vertices
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            let edge_keys: Vec<_> = self.edges
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            info!("Flushed {} bytes after deleting vertex at {:?}, current vertices keys: {:?}, edges keys: {:?}", bytes_flushed, self.db_path, vertex_keys, edge_keys);
            #[cfg(feature = "with-openraft-sled")]
            {
                let request = openraft::raft::ClientWriteRequest::new(
                    openraft::EntryPayload::AppWrite {
                        key: key.to_vec(),
                        value: vec![],
                    }
                );
                self.raft.client_write(request).await
                    .map_err(|e| GraphError::StorageError(format!("Raft vertex delete failed: {}", e)))?;
                info!("Raft vertex delete replicated at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during delete_vertex".to_string()))?
    }

    pub async fn create_edge(&self, edge: &Edge) -> GraphResult<()> {
        self.ensure_write_access().await?;
        let key = create_edge_key(&edge.outbound_id.into(), &edge.t, &edge.inbound_id.into())?;
        let value = Self::serialize_to_ivec(edge)?;
        info!("Creating edge ({}, {}, {}) at path {:?}", edge.outbound_id, edge.t, edge.inbound_id, self.db_path);

        timeout(Duration::from_secs(5), async {
            let mut batch = Batch::default();
            batch.insert(&*key, value);
            self.edges
                .apply_batch(batch)
                .map_err(|e| GraphError::StorageError(format!("Failed to apply batch for edge: {}", e)))?;

            let bytes_flushed = self.db
                .flush_async()
                .await
                .map_err(|e| GraphError::StorageError(format!("Failed to flush DB: {}", e)))?;
            info!("Flushed {} bytes after creating edge at {:?}", bytes_flushed, self.db_path);

            let persisted = self.edges
                .get(&key)
                .map_err(|e| GraphError::StorageError(format!("Failed to verify edge insert: {}", e)))?;
            if persisted.is_none() {
                error!("Persistence verification failed for edge ({}, {}, {}) at {:?}", 
                    edge.outbound_id, edge.t, edge.inbound_id, self.db_path);
                return Err(GraphError::StorageError("Edge insert not persisted".to_string()));
            }

            let edge_keys: Vec<_> = self.edges
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            info!("Current edges keys at {:?}: {:?}", self.db_path, edge_keys);

            #[cfg(feature = "with-openraft-sled")]
            {
                let request = openraft::raft::ClientWriteRequest::new(
                    openraft::EntryPayload::AppWrite {
                        key: key.to_vec(),
                        value: edge.t.to_string().into_bytes(),
                    }
                );
                self.raft.client_write(request).await
                    .map_err(|e| GraphError::StorageError(format!("Raft edge create failed: {}", e)))?;
                info!("Raft edge create replicated at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during create_edge".to_string()))?
    }

    pub async fn get_edge(
        &self,
        outbound_id: &Uuid,
        edge_type: &Identifier,
        inbound_id: &Uuid,
    ) -> GraphResult<Option<Edge>> {
        if !self.is_running().await {
            return Err(GraphError::StorageError(format!("Daemon at path {:?} is not running", self.db_path)));
        }
        let key = create_edge_key(&(*outbound_id).into(), edge_type, &(*inbound_id).into())?;
        info!("Retrieving edge ({}, {}, {}) from path {:?}", outbound_id, edge_type, inbound_id, self.db_path);

        let res = timeout(Duration::from_secs(5), async {
            let opt = self.edges
                .get(&key)
                .map_err(|e| GraphError::StorageError(format!("Failed to retrieve edge: {}", e)))?;
            match opt {
                Some(ivec) => {
                    let edge = Self::deserialize_from_ivec(ivec)?;
                    Ok::<Option<Edge>, GraphError>(Some(edge))
                }
                None => Ok::<Option<Edge>, GraphError>(None),
            }
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during get_edge".to_string()))??;

        let edge_keys: Vec<_> = self.edges
            .iter()
            .keys()
            .filter_map(|k| k.ok())
            .collect();
        info!("Current edges keys at {:?}: {:?}", self.db_path, edge_keys);
        Ok(res)
    }

    pub async fn update_edge(&self, edge: &Edge) -> GraphResult<()> {
        self.create_edge(edge).await
    }

    pub async fn delete_edge(
        &self,
        outbound_id: &Uuid,
        edge_type: &Identifier,
        inbound_id: &Uuid,
    ) -> GraphResult<()> {
        self.ensure_write_access().await?;
        let key = create_edge_key(&(*outbound_id).into(), edge_type, &(*inbound_id).into())?;
        info!("Deleting edge ({}, {}, {}) from path {:?}", outbound_id, edge_type, inbound_id, self.db_path);
        timeout(Duration::from_secs(5), async {
            self.edges
                .remove(key)
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let bytes_flushed = self.db
                .flush_async()
                .await
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let edge_keys: Vec<_> = self.edges
                .iter()
                .keys()
                .filter_map(|k| k.ok())
                .collect();
            info!("Flushed {} bytes after deleting edge at {:?}, current edges keys: {:?}", bytes_flushed, self.db_path, edge_keys);
            #[cfg(feature = "with-openraft-sled")]
            {
                let request = openraft::raft::ClientWriteRequest::new(
                    openraft::EntryPayload::AppWrite {
                        key: key.to_vec(),
                        value: vec![],
                    }
                );
                self.raft.client_write(request).await
                    .map_err(|e| GraphError::StorageError(format!("Raft edge delete failed: {}", e)))?;
                info!("Raft edge delete replicated at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during delete_edge".to_string()))?
    }

    pub async fn force_reset(&self) -> GraphResult<()> {
        info!("Resetting SledDaemon at path {:?}", self.db_path);
        timeout(Duration::from_secs(5), async {
            self.db
                .clear()
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            let bytes_flushed = self.db
                .flush_async()
                .await
                .map_err(|e| GraphError::StorageError(e.to_string()))?;
            info!("Flushed {} bytes after resetting daemon at {:?}", bytes_flushed, self.db_path);
            #[cfg(feature = "with-openraft-sled")]
            {
                self.raft_storage
                    .reset()
                    .await
                    .map_err(|e| GraphError::StorageError(format!("Raft reset failed: {}", e)))?;
                info!("Raft storage reset at {:?}", self.db_path);
            }
            Ok(())
        })
        .await
        .map_err(|_| GraphError::StorageError("Timeout during force_reset".to_string()))?
    }

    pub async fn force_unlock(&self) -> GraphResult<()> {
        // Intentionally empty to avoid lock cleanup
        Ok(())
    }

    pub async fn force_unlock_path(_path: &Path) -> GraphResult<()> {
        // Intentionally empty to avoid lock cleanup
        Ok(())
    }
}

impl SledDaemonPool {
    pub fn new() -> Self {
        Self {
            daemons: HashMap::new(),
            registry: Arc::new(RwLock::new(HashMap::new())),
            initialized: Arc::new(RwLock::new(false)),
        }
    }

    pub async fn add_daemon(&mut self, storage_config: &StorageConfig, port: u16, config: &SledConfig) -> GraphResult<()> {
        // Check if port is already in use
        let mut system = System::new_all();
        system.refresh_all();
        let port_in_use = system.processes().values().any(|proc| {
            proc.cmd().iter().any(|arg| arg.to_string_lossy().contains(&port.to_string())) && 
            proc.name().to_string_lossy().contains("graphdb")
        });
        if port_in_use {
            error!("Port {} is already in use by another process", port);
            return Err(GraphError::StorageError(format!("Port {} is already in use", port)));
        }

        // Ensure the port is explicitly set in the config
        let mut port_config = config.clone();
        port_config.port = Some(port);

        // Check for existing daemon in pool
        if self.daemons.contains_key(&port) {
            error!("Daemon already exists on port {}", port);
            return Err(GraphError::StorageError(format!("Daemon already exists on port {}", port)));
        }

        // Check daemon registry without cleanup
        if GLOBAL_DAEMON_REGISTRY.get_daemon_metadata(port).await?.is_some() {
            warn!("Storage process already registered on port {}. Skipping cleanup.", port);
            // Do not unregister or clean locks
        }

        // Create new daemon
        let daemon = Arc::new(SledDaemon::new(&port_config).await?);
        self.daemons.insert(port, daemon.clone());

        // Register daemon in registry
        let metadata = DaemonMetadata {
            service_type: "storage".to_string(),
            port,
            pid: std::process::id(),
            ip_address: "127.0.0.1".to_string(),
            data_dir: Some(port_config.path.clone()),
            config_path: Some(storage_config.config_root_directory.join("storage_config.yaml")),
            engine_type: Some("sled".to_string()),
            last_seen_nanos: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_nanos() as i64)
                .unwrap_or(0),
        };
        self.registry.write().await.insert(port, metadata.clone());
        GLOBAL_DAEMON_REGISTRY
            .register_daemon(metadata)
            .await
            .map_err(|e| GraphError::StorageError(format!("Failed to register daemon in GLOBAL_DAEMON_REGISTRY: {}", e)))?;
        info!("Added daemon for port {} at path {:?}", port, port_config.path);
        Ok(())
    }

    pub async fn initialize_cluster(&mut self, storage_config: &StorageConfig, config: &SledConfig, cli_port: Option<u16>) -> GraphResult<()> {
        let mut initialized = self.initialized.write().await;
        if *initialized {
            warn!("SledDaemonPool already initialized, skipping. Caller stack trace: {:#?}", std::backtrace::Backtrace::capture());
            return Ok(());
        }

        debug!("Initializing cluster with use_raft_for_scale: {}", storage_config.use_raft_for_scale);

        let registry_path = Path::new(DAEMON_REGISTRY_DB_PATH);
        if let Some(parent) = registry_path.parent() {
            debug!("Ensuring daemon registry directory exists: {:?}", parent);
            fs::create_dir_all(parent)
                .await
                .map_err(|e| {
                    error!("Failed to create daemon registry directory {:?}: {}", parent, e);
                    GraphError::Io(e)
                })?;
        }

        // Use CLI-specified port if provided, otherwise use default_port from config
        let port = cli_port.unwrap_or(storage_config.default_port);
        if !storage_config.use_raft_for_scale {
            info!("use_raft_for_scale is false, using port {}", port);
            drop(initialized);
            self.add_daemon(storage_config, port, config).await?;
            *self.initialized.write().await = true;
            return Ok(());
        }

        // For Raft mode, initialize a single daemon (no cluster range)
        let mut system = System::new_all();
        system.refresh_all();
        let port_in_use = system.processes().values().any(|proc| {
            proc.cmd().iter().any(|arg| arg.to_string_lossy().contains(&port.to_string())) && 
            proc.name().to_string_lossy().contains("graphdb")
        });
        if port_in_use {
            error!("Port {} is already in use by another process", port);
            return Err(GraphError::StorageError(format!("Port {} is already in use", port)));
        }

        if GLOBAL_DAEMON_REGISTRY.get_daemon_metadata(port).await?.is_some() {
            warn!("Storage process already registered on port {}. Skipping cleanup.", port);
            // Do not unregister or clean locks
        }

        info!("Initializing single daemon for port {}", port);
        let mut port_config = config.clone();
        port_config.port = Some(port);
        let daemon = Arc::new(SledDaemon::new(&port_config).await?);
        self.daemons.insert(port, daemon.clone());
        let metadata = DaemonMetadata {
            service_type: "storage".to_string(),
            port,
            pid: std::process::id(),
            ip_address: "127.0.0.1".to_string(),
            data_dir: Some(port_config.path.clone()),
            config_path: Some(storage_config.config_root_directory.join("storage_config.yaml")),
            engine_type: Some("sled".to_string()),
            last_seen_nanos: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_nanos() as i64)
                .unwrap_or(0),
        };
        self.registry.write().await.insert(port, metadata.clone());
        GLOBAL_DAEMON_REGISTRY
            .register_daemon(metadata)
            .await
            .map_err(|e| {
                error!("Failed to register daemon on port {}: {}", port, e);
                GraphError::StorageError(format!("Failed to register daemon on port {}: {}", port, e))
            })?;

        #[cfg(feature = "with-openraft-sled")]
        {
            let node_id = port as u64;
            let raft = &daemon.raft;
            let initial_nodes = HashMap::from([(node_id, BasicNode { addr: format!("127.0.0.1:{}", port) })]);
            raft.initialize(initial_nodes).await
                .map_err(|e| {
                    error!("Failed to initialize Raft for node {}: {}", node_id, e);
                    GraphError::StorageError(format!("Failed to initialize Raft for node {}: {}", node_id, e))
                })?;
            info!("Initialized Raft for node {} on port {}", node_id, port);
        }

        *initialized = true;
        info!("Successfully initialized daemon on port {}", port);
        Ok(())
    }

    pub async fn any_daemon(&self) -> GraphResult<Arc<SledDaemon>> {
        if let Some(daemon) = self.daemons.values().next() {
            info!("Selected daemon on port {} at path {:?}", daemon.port(), daemon.db_path());
            Ok(Arc::clone(daemon))
        } else {
            error!("No daemons available in the pool");
            Err(GraphError::StorageError("No daemons available".to_string()))
        }
    }

    pub async fn close(&self, _port: Option<u16>) -> GraphResult<()> {
        let futures = self.daemons.values().map(|daemon| async {
            let db_path = daemon.db_path();
            match timeout(Duration::from_secs(10), daemon.close()).await {
                Ok(Ok(())) => {
                    info!("Closed daemon at {:?}", db_path);
                    Ok(())
                }
                Ok(Err(e)) => {
                    error!("Failed to close daemon at {:?}: {}", db_path, e);
                    Err(GraphError::StorageError(e.to_string()))
                }
                Err(_) => {
                    error!("Timeout closing daemon at {:?}", db_path);
                    Err(GraphError::StorageError(format!("Timeout closing daemon at {:?}", db_path)))
                }
            }
        });
        let results = join_all(futures).await;
        let errors: Vec<_> = results.into_iter().filter_map(|r| r.err()).collect();
        if !errors.is_empty() {
            error!("Errors during close: {:?}", errors);
            return Err(GraphError::StorageError(format!("Close errors: {:?}", errors)));
        }
        info!("Successfully closed all daemons");
        Ok(())
    }

    pub async fn leader_daemon(&self) -> GraphResult<Arc<SledDaemon>> {
        for daemon in self.daemons.values() {
            #[cfg(feature = "with-openraft-sled")]
            {
                if daemon.is_leader().await? {
                    info!("Selected leader daemon on port {} at path {:?}", daemon.port(), daemon.db_path());
                    return Ok(Arc::clone(daemon));
                }
            }
            #[cfg(not(feature = "with-openraft-sled"))]
            {
                info!("Selected daemon on port {} at path {:?}", daemon.port(), daemon.db_path());
                return Ok(Arc::clone(daemon));
            }
        }
        error!("No leader daemon found in the pool");
        Err(GraphError::StorageError("No leader daemon found".to_string()))
    }

    pub async fn create_edge(&self, edge: Edge, _use_raft: bool) -> GraphResult<()> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.create_edge(&edge)).await
            .map_err(|_| GraphError::StorageError("Timeout during create_edge".to_string()))?
    }

    pub async fn get_edge(
        &self,
        outbound_id: &Uuid,
        edge_type: &Identifier,
        inbound_id: &Uuid,
        _use_raft: bool,
    ) -> GraphResult<Option<Edge>> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.get_edge(outbound_id, edge_type, inbound_id)).await
            .map_err(|_| GraphError::StorageError("Timeout during get_edge".to_string()))?
    }

    pub async fn update_edge(&self, edge: Edge, _use_raft: bool) -> GraphResult<()> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.update_edge(&edge)).await
            .map_err(|_| GraphError::StorageError("Timeout during update_edge".to_string()))?
    }

    pub async fn delete_edge(
        &self,
        outbound_id: &Uuid,
        edge_type: &Identifier,
        inbound_id: &Uuid,
        _use_raft: bool,
    ) -> GraphResult<()> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.delete_edge(outbound_id, edge_type, inbound_id)).await
            .map_err(|_| GraphError::StorageError("Timeout during delete_edge".to_string()))?
    }

    pub async fn create_vertex(&self, vertex: Vertex, _use_raft: bool) -> GraphResult<()> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.create_vertex(&vertex)).await
            .map_err(|_| GraphError::StorageError("Timeout during create_vertex".to_string()))?
    }

    pub async fn get_vertex(&self, id: &Uuid, _use_raft: bool) -> GraphResult<Option<Vertex>> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.get_vertex(id)).await
            .map_err(|_| GraphError::StorageError("Timeout during get_vertex".to_string()))?
    }

    pub async fn update_vertex(&self, vertex: Vertex, _use_raft: bool) -> GraphResult<()> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.update_vertex(&vertex)).await
            .map_err(|_| GraphError::StorageError("Timeout during update_vertex".to_string()))?
    }

    pub async fn delete_vertex(&self, id: &Uuid, _use_raft: bool) -> GraphResult<()> {
        let daemon = self.leader_daemon().await?;
        timeout(Duration::from_secs(5), daemon.delete_vertex(id)).await
            .map_err(|_| GraphError::StorageError("Timeout during delete_vertex".to_string()))?
    }
}

#[cfg(feature = "with-openraft-sled")]
#[async_trait]
impl RaftNetwork<NodeId, BasicNode> for RaftTcpNetwork {
    async fn send_append_entries(
        &self,
        target: NodeId,
        rpc: openraft::raft::AppendEntriesRequest<BasicNode>,
    ) -> Result<openraft::raft::AppendEntriesResponse, openraft::error::RPCError<NodeId, BasicNode>> {
        const MAX_RETRIES: u32 = 3;
        const BASE_DELAY_MS: u64 = 100;
        let addr = format!("127.0.0.1:{}", target);
        let mut attempt = 0;

        loop {
            match timeout(Duration::from_secs(2), async {
                let mut stream = TcpStream::connect(&addr).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let request_data = serde_json::to_vec(&rpc)
                    .map_err(|e| openraft::error::RPCError::PayloadTooLarge {
                        error: openraft::error::ClientError::new(&e, target, &addr),
                    })?;
                stream.write_all(&request_data).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                stream.flush().await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let mut buffer = Vec::new();
                stream.read_to_end(&mut buffer).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let response: openraft::raft::AppendEntriesResponse = serde_json::from_slice(&buffer)
                    .map_err(|e| openraft::error::RPCError::PayloadTooLarge {
                        error: openraft::error::ClientError::new(&e, target, &addr),
                    })?;
                Ok(response)
            })
            .await
            {
                Ok(Ok(response)) => return Ok(response),
                Ok(Err(e)) if attempt < MAX_RETRIES => {
                    warn!("Failed to send append entries to {} on attempt {}: {}. Retrying.", addr, attempt + 1, e);
                    attempt += 1;
                    tokio::time::sleep(Duration::from_millis(BASE_DELAY_MS * (attempt as u64 + 1))).await;
                    continue;
                }
                Ok(Err(e)) => {
                    error!("Failed to send append entries to {} after {} attempts: {}", addr, attempt + 1, e);
                    return Err(e);
                }
                Err(_) => {
                    warn!("Timeout sending append entries to {} on attempt {}. Retrying.", addr, attempt + 1);
                    attempt += 1;
                    if attempt >= MAX_RETRIES {
                        error!("Timeout sending append entries to {} after {} attempts.", addr, MAX_RETRIES);
                        return Err(openraft::error::RPCError::Network {
                            error: openraft::error::NetworkError::new(&std::io::Error::new(
                                std::io::ErrorKind::TimedOut,
                                "Timeout sending append entries",
                            )),
                            target,
                            node: BasicNode { addr },
                        });
                    }
                    tokio::time::sleep(Duration::from_millis(BASE_DELAY_MS * (attempt as u64 + 1))).await;
                }
            }
        }
    }

    async fn send_install_snapshot(
        &self,
        target: NodeId,
        rpc: openraft::raft::InstallSnapshotRequest<BasicNode>,
    ) -> Result<openraft::raft::InstallSnapshotResponse, openraft::error::RPCError<NodeId, BasicNode>> {
        const MAX_RETRIES: u32 = 3;
        const BASE_DELAY_MS: u64 = 100;
        let addr = format!("127.0.0.1:{}", target);
        let mut attempt = 0;

        loop {
            match timeout(Duration::from_secs(2), async {
                let mut stream = TcpStream::connect(&addr).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let request_data = serde_json::to_vec(&rpc)
                    .map_err(|e| openraft::error::RPCError::PayloadTooLarge {
                        error: openraft::error::ClientError::new(&e, target, &addr),
                    })?;
                stream.write_all(&request_data).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                stream.flush().await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let mut buffer = Vec::new();
                stream.read_to_end(&mut buffer).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let response: openraft::raft::InstallSnapshotResponse = serde_json::from_slice(&buffer)
                    .map_err(|e| openraft::error::RPCError::PayloadTooLarge {
                        error: openraft::error::ClientError::new(&e, target, &addr),
                    })?;
                Ok(response)
            })
            .await
            {
                Ok(Ok(response)) => return Ok(response),
                Ok(Err(e)) if attempt < MAX_RETRIES => {
                    warn!("Failed to send install snapshot to {} on attempt {}: {}. Retrying.", addr, attempt + 1, e);
                    attempt += 1;
                    tokio::time::sleep(Duration::from_millis(BASE_DELAY_MS * (attempt as u64 + 1))).await;
                    continue;
                }
                Ok(Err(e)) => {
                    error!("Failed to send install snapshot to {} after {} attempts: {}", addr, attempt + 1, e);
                    return Err(e);
                }
                Err(_) => {
                    warn!("Timeout sending install snapshot to {} on attempt {}. Retrying.", addr, attempt + 1);
                    attempt += 1;
                    if attempt >= MAX_RETRIES {
                        error!("Timeout sending install snapshot to {} after {} attempts.", addr, MAX_RETRIES);
                        return Err(openraft::error::RPCError::Network {
                            error: openraft::error::NetworkError::new(&std::io::Error::new(
                                std::io::ErrorKind::TimedOut,
                                "Timeout sending install snapshot",
                            )),
                            target,
                            node: BasicNode { addr },
                        });
                    }
                    tokio::time::sleep(Duration::from_millis(BASE_DELAY_MS * (attempt as u64 + 1))).await;
                }
            }
        }
    }

    async fn send_vote(
        &self,
        target: NodeId,
        rpc: openraft::raft::VoteRequest<NodeId>,
    ) -> Result<openraft::raft::VoteResponse<NodeId>, openraft::error::RPCError<NodeId, BasicNode>> {
        const MAX_RETRIES: u32 = 3;
        const BASE_DELAY_MS: u64 = 100;
        let addr = format!("127.0.0.1:{}", target);
        debug!("Sending vote to node {} at {}", target, addr);
        let mut attempt = 0;

        loop {
            match timeout(Duration::from_secs(2), async {
                let mut stream = TcpStream::connect(&addr).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let request_data = serde_json::to_vec(&rpc)
                    .map_err(|e| openraft::error::RPCError::PayloadTooLarge {
                        error: openraft::error::ClientError::new(&e, target, &addr),
                    })?;
                stream.write_all(&request_data).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                stream.flush().await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let mut buffer = Vec::new();
                stream.read_to_end(&mut buffer).await
                    .map_err(|e| openraft::error::RPCError::Network {
                        error: openraft::error::NetworkError::new(&e),
                        target,
                        node: BasicNode { addr: addr.clone() },
                    })?;
                let response: openraft::raft::VoteResponse<NodeId> = serde_json::from_slice(&buffer)
                    .map_err(|e| openraft::error::RPCError::PayloadTooLarge {
                        error: openraft::error::ClientError::new(&e, target, &addr),
                    })?;
                Ok(response)
            })
            .await
            {
                Ok(Ok(response)) => return Ok(response),
                Ok(Err(e)) if attempt < MAX_RETRIES => {
                    warn!("Failed to send vote to {} on attempt {}: {}. Retrying.", addr, attempt + 1, e);
                    attempt += 1;
                    tokio::time::sleep(Duration::from_millis(BASE_DELAY_MS * (attempt as u64 + 1))).await;
                    continue;
                }
                Ok(Err(e)) => {
                    error!("Failed to send vote to {} after {} attempts: {}", addr, attempt + 1, e);
                    return Err(e);
                }
                Err(_) => {
                    warn!("Timeout sending vote to {} on attempt {}. Retrying.", addr, attempt + 1);
                    attempt += 1;
                    if attempt >= MAX_RETRIES {
                        error!("Timeout sending vote to {} after {} attempts.", addr, MAX_RETRIES);
                        return Err(openraft::error::RPCError::Network {
                            error: openraft::error::NetworkError::new(&std::io::Error::new(
                                std::io::ErrorKind::TimedOut,
                                "Timeout sending vote",
                            )),
                            target,
                            node: BasicNode { addr },
                        });
                    }
                    tokio::time::sleep(Duration::from_millis(BASE_DELAY_MS * (attempt as u64 + 1))).await;
                }
            }
        }
    }
}